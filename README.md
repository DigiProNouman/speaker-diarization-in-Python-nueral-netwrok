# speaker-diarization-in-Python-nueral-netwrok
perform simultaneous speaker recognition using features such as MFCCs, Zero Crossing Rate, etc and an HMM classifier or a Neural Network 
in python.
The code should get as inputs wav files and then give me time instances of when each speaker has spoken
Having wav files as inputs for the training system to train for each speaker and then for testing one wav file where multiple speakers will be talking. The system should output the time instances in which each one has talked.
The more graphs the code has the better. Or if it can be done in a gui using PyQt4 it would be the best.
